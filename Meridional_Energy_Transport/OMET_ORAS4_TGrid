#!/usr/bin/env python

"""
Copyright Netherlands eScience Center

Function        : Quantify oceanic meridional energy transport (ORAS4)
Author          : Yang Liu
Date            : 2017.8.30
Last Update     : 2017.9.19
Description     : The code aims to calculate the oceanic meridional energy
                  transport based on oceanic reanalysis dataset ORAS4
                  from ECMWF. The complete computaiton is accomplished on model
                  level (original ORCA1_z42 grid). All the interpolations are made
                  on the T grid. The procedure is generic and is able to adapt any
                  atmospheric reanalysis datasets, with some changes.

Return Value    : NetCFD4 data file
Dependencies    : os, time, numpy, netCDF4, sys, matplotlib, logging
variables       : Potential Temperature                     Theta
                  Sea Water Density                         rho
                  Specific Heat Capacity of Sea Water       cp
                  Zonal Current Velocity                    u
                  Meridional Current Velocity               v
                  Land-Sea Mask
                  Zonal Grid Spacing Scale Factors          e1
                  Meridional Grid Spacing Scale Factors     e2

Caveat!!        : The full dataset is from 1958. However, a quality report from
                  Magdalena from ECMWF indicates the quality of data for the first
                  two decades are very poor. Hence we use the data from 1979. which
                  is the start of satellite era.
"""
import numpy as np
import seaborn as sns
#import scipy as sp
import time as tttt
from netCDF4 import Dataset,num2date
import os
import platform
import sys
import logging
import matplotlib
# generate images without having a window appear
#matplotlib.use('Agg')
import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap, cm
import cartopy.crs as ccrs
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import iris
import iris.plot as iplt
import iris.quickplot as qplt

##########################################################################
###########################   Units vacabulory   #########################
# cpT:  [J / kg C] * [C]     = [J / kg]
# v*rho cpT dxdz = [m/s] * [J / kg] * [kg/m3] * m * m = [J / s] = [Wat]

# gz in [m2 / s2] = [ kg m2 / kg s2 ] = [J / kg]
##########################################################################

# print the system structure and the path of the kernal
print platform.architecture()
print os.path

# switch on the seaborn effect
sns.set()

# calculate the time for the code execution
start_time = tttt.time()

# Redirect all the console output to a file
#sys.stdout = open('F:\DataBase\ORAS4\console.out','w')
#sys.stdout = open('/project/Reanalysis/ORAS4/console_E.out','w')

# logging level 'DEBUG' 'INFO' 'WARNING' 'ERROR' 'CRITICAL'
#logging.basicConfig(filename = 'F:\DataBase\ORAS4\history.log', filemode = 'w',level = logging.DEBUG,format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
#logging.basicConfig(filename = '/project/Reanalysis/ORAS4/history_E.log',
#                    filemode = 'w', level = logging.DEBUG,
#                    format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# define the constant:
constant ={'g' : 9.80616,      # gravititional acceleration [m / s2]
           'R' : 6371009,      # radius of the earth [m]
           'cp': 3987,         # heat capacity of sea water [J/(Kg*C)]
           'rho': 1027,        # sea water density [Kg/m3]
            }

################################   Input zone  ######################################
# specify data path
datapath = 'F:\DataBase\ORAS\ORAS4\Monthly\model'
#datapath = '/project/Reanalysis/ORAS4'
# time of the data, which concerns with the name of input
# starting time (year)
start_year = 1980
# Ending time, if only for 1 year, then it should be the same as starting year
end_year = 1980
# specify output path for the netCDF4 file
output_path_fig = 'C:\Yang\PhD\Computation and Modeling\Blue Action\OMET\ORAS4'
#output_path = '/project/Reanalysis/ERA_Interim/Subdaily/Model'
# benchmark datasets for basic dimensions
#benchmark_path = 'F:\DataBase\ORAS\ORAS4\Monthly\model\\thetao_oras4_1m_1979_grid_T.nc'
#benchmark = Dataset(benchmark_path)
####################################################################################

def var_key(datapath, year):
    # get the path to each datasets
    print "Start retrieving datasets"
    #logging.info("Start retrieving variables theta,s,u,v for from %d (y)" % (year)
    datapath_theta = datapath + os.sep + 'theta' + os.sep + 'thetao_oras4_1m_%d_grid_T.nc' % (year)
    datapath_s = datapath + os.sep + 's' + os.sep + 'so_oras4_1m_%d_grid_T.nc' % (year)
    datapath_u = datapath + os.sep + 'u' + os.sep + 'uo_oras4_1m_%d_grid_U.nc' % (year)
    datapath_v = datapath + os.sep + 'v' + os.sep + 'vo_oras4_1m_%d_grid_V.nc' % (year)

    # get the variable keys
    theta_key = Dataset(datapath_theta)
    s_key = Dataset(datapath_s)
    u_key = Dataset(datapath_u)
    v_key = Dataset(datapath_v)

    print "Retrieving datasets for the year %d successfully!" % (year)
    #logging.info("Retrieving variables for the year %d successfully!" % (year))
    return theta_key, s_key, u_key, v_key

def var_coordinate(datapath):
    print "Start retrieving the datasets of ORCA1 coordinate and mask info"
    #logging.info('Start retrieving the datasets of ORCA1 coordinate and mask info')
    # get the variable keys
    mesh_mask_key = Dataset(datapath+ os.sep + 'mesh_mask.nc')
    #grid_T_key = Dataset(datapath+ os.sep + 'coordinates_grid_T.nc')
    #grid_U_key = Dataset(datapath+ os.sep + 'coordinates_grid_U.nc')
    #grid_V_key = Dataset(datapath+ os.sep + 'coordinates_grid_V.nc')
    #extract variables
    # lat-lon-depth coordinate info
    nav_lat = mesh_mask_key.variables['nav_lat'][:]
    nav_lon = mesh_mask_key.variables['nav_lon'][:]
    nav_lev = mesh_mask_key.variables['nav_lev'][:]
    # land-sea mask
    tmask = mesh_mask_key.variables['tmask'][0,:,:,:]
    umask = mesh_mask_key.variables['umask'][0,:,:,:]
    vmask = mesh_mask_key.variables['vmask'][0,:,:,:]
    # grid spacing scale factors (zonal)
    e1t = mesh_mask_key.variables['e1t'][0,:,:]
    e2t = mesh_mask_key.variables['e2t'][0,:,:]
    e1u = mesh_mask_key.variables['e1u'][0,:,:]
    e2u = mesh_mask_key.variables['e2u'][0,:,:]
    e1v = mesh_mask_key.variables['e1v'][0,:,:]
    e2v = mesh_mask_key.variables['e2v'][0,:,:]
    # take the bathymetry
    mbathy = mesh_mask_key.variables['mbathy'][0,:,:]
    # comparison between variables
    #lat_grid_T = grid_T_key.variables['lat'][:]
    #lon_grid_T = grid_T_key.variables['lon'][:]
    #tmask_grid_T = grid_T_key.variables['tmask'][:]

    #lat_grid_U = grid_U_key.variables['lat'][:]
    #lon_grid_U = grid_U_key.variables['lon'][:]
    #umask_grid_U = grid_U_key.variables['umask'][:]

    #lat_grid_V = grid_V_key.variables['lat'][:]
    #lon_grid_V = grid_V_key.variables['lon'][:]
    #vmask_grid_V = grid_V_key.variables['vmask'][:]

    #Comparison
    #print 'The tmask file from mesh_mask.nc and the grid T are the same %s' % \
    #       np.array_equal(tmask,tmask_grid_T)

    return nav_lat, nav_lon, nav_lev, tmask, umask, vmask, e1t, e2t, mbathy

def mass_correction_direct(u_key, v_key):
    # extract variables
    u = u_key.variables['uo'][:]
    v = v_key.variables['vo'][:]
    # calculate the mass residual based on continuity equation (divergence free for incompressible fluid)
    # calculate the depth level matrix
    dz = np.zeros(nav_lev.shape)
    for i in np.arange(len(nav_lev)):
        if i == 0:
            dz[i] = nav_lev[i]
        else:
            dz[i] = nav_lev[i] - nav_lev[i-1]
    # calculate the mass flux
    mass_flux_u = np.zeros((len(index_month),level,jj,ji),dtype=float)
    mass_flux_v = np.zeros((len(index_month),level,jj,ji),dtype=float)
    for i in np.arange(level):
            mass_flux_u[:,i,:,:] = u[:,i,:,:] * dz[i]
            mass_flux_v[:,i,:,:] = v[:,i,:,:] * dz[i]
    # take the vertical integral
    mass_flux_u_int = np.sum(mass_flux_u,1)
    mass_flux_v_int = np.sum(mass_flux_v,1)
    # calculate the divergence of flux
    div_mass_flux_u = np.zeros((len(index_month),jj,ji),dtype=float)
    div_mass_flux_v = np.zeros((len(index_month),jj,ji),dtype=float)

    for i in np.arange(len(index_month)):
        for j in np.arange(ji):
            if j == 0:
                div_mass_flux_u[i,:,j] = (mass_flux_u_int[i,:,j] - mass_flux_u_int[i,:,-1]) / e1t[:,j]
            else:
                div_mass_flux_u[i,:,j] = (mass_flux_u_int[i,:,j] - mass_flux_u_int[i,:,j-1]) / e1t[:,j]

    for i in np.arange(len(index_month)):
        for j in np.arange(jj):
            if j == 0:
                div_mass_flux_v[i,j,:] = mass_flux_v_int[i,j,:] / e2t[j,:]
            else:
                div_mass_flux_v[i,j,:] = (mass_flux_v_int[i,j,:] - mass_flux_v_int[i,j-1,:]) / e2t[j,:]
    # define the mass transport matrix at each grid point
    mass_residual = np.zeros((len(index_month),jj,ji),dtype=float)
    # calculate the mass residual based on continuity equation
    mass_residual = div_mass_flux_u + div_mass_flux_v
    # create the velocity correction matrix
    uc = np.zeros((len(index_month),jj,ji),dtype=float)
    vc = np.zeros((len(index_month),jj,ji),dtype=float)
    for i in np.arange(len(index_month)):
        uc[i,:,:] = mass_residual[i,:,:] * e1t / bathymetry * surface_mask
        vc[i,:,:] = mass_residual[i,:,:] * e2t / bathymetry * surface_mask

    return uc, vc

def mass_correction_modified(u_key, v_key, bathymetry):
    #dominant equation for stream function
    # psi = e1v(m) * rho(kg/m3) * v(m/s) * dz(m) = (kg/s)
    # extract variables
    u = u_key.variables['uo'][:]
    v = v_key.variables['vo'][:]
    # interpolate u and v on T grid through nearest neighbour method
    u_Tgrid = np.zeros((len(index_month),level,jj,ji),dtype=float)
    v_Tgrid = np.zeros((len(index_month),level,jj,ji),dtype=float)
    # u -> T grid
    for i in np.arange(ji):
        if i == 0:
            u_Tgrid[:,:,:,i] = (u[:,:,:,i] + u[:,:,:,-1]) / 2
        elif i == ji-1:
            u_Tgrid[:,:,:,i] = (u[:,:,:,0] + u[:,:,:,i]) / 2
        else:
            u_Tgrid[:,:,:,i] = (u[:,:,:,i] + u[:,:,:,i-1]) / 2
    # v -> T grid
    for i in np.arange(jj):
        if i == 0:
            v_Tgrid[:,:,i,:] = v[:,:,i,:]
        else:
            v_Tgrid[:,:,i,:] = (v[:,:,i,:]+ v[:,:,i-1,:]) / 2
    # clear the interpolated velocity field by the masked grid
    for i in np.arange(len(index_month)):
        u_Tgrid[i,:,:,:] = u_Tgrid[i,:,:,:] * tmask
        v_Tgrid[i,:,:,:] = v_Tgrid[i,:,:,:] * tmask
    # calculate the mass residual based on continuity equation (divergence free for incompressible fluid)
    # calculate the depth level matrix
    dz = np.zeros(nav_lev.shape)
    for i in np.arange(len(nav_lev)):
        if i == 0:
            dz[i] = nav_lev[i]
        else:
            dz[i] = nav_lev[i] - nav_lev[i-1]
    # expand depth matrix
    dz_2D = np.repeat(dz[np.newaxis,:],len(index_month),0)
    dz_3D = np.repeat(dz_2D[:,:,np.newaxis],jj,2)
    dz_4D = np.repeat(dz_3D[:,:,:,np.newaxis],ji,3)
    # calculate the mass flux
    mass_flux_u = np.sum(u_Tgrid * dz_4D,1)
    mass_flux_v = np.sum(v_Tgrid * dz_4D,1)
    # calculate the divergence of mass flux
    div_mass_flux_u = np.zeros((len(index_month),jj,ji),dtype=float)
    div_mass_flux_v = np.zeros((len(index_month),jj,ji),dtype=float)

    e1t_3D = np.repeat(e1t[np.newaxis,:,:],len(index_month),0)
    e2t_3D = np.repeat(e2t[np.newaxis,:,:],len(index_month),0)

    for i in np.arange(ji):
        if i == 0:
            div_mass_flux_u[:,:,i] = (mass_flux_u[:,:,i+1] - mass_flux_u[:,:,-1]) / (e1t_3D[:,:,i+1]/2 + e1t_3D[:,:,i] + e1t_3D[:,:,-1]/2)
        elif i == ji-1:
            div_mass_flux_u[:,:,i] = (mass_flux_u[:,:,0] - mass_flux_u[:,:,i-1]) / (e1t_3D[:,:,0]/2 + e1t_3D[:,:,i] + e1t_3D[:,:,i-1]/2)
        else:
            div_mass_flux_u[:,:,i] = (mass_flux_u[:,:,i+1] - mass_flux_u[:,:,i-1]) / (e1t_3D[:,:,i+1]/2 + e1t_3D[:,:,i] + e1t_3D[:,:,i-1]/2)

    for i in np.arange(jj):
        if i == 0:
            div_mass_flux_v[:,i,:] = (mass_flux_v[:,i+1,:] - mass_flux_v[:,i,:]) / (e2t_3D[:,i+1,:]/2 + e2t_3D[:,i,:]/2)
        elif i == jj-1:
            div_mass_flux_v[:,i,:] = (mass_flux_v[:,i,:] - mass_flux_v[:,i-1,:]) / (e2t_3D[:,i,:]/2 + e2t_3D[:,i-1,:]/2)
        else:
            div_mass_flux_v[:,i,:] = (mass_flux_v[:,i+1,:] - mass_flux_v[:,i-1,:]) / (e2t_3D[:,i+1,:]/2 + e2t_3D[:,i,:] + e2t_3D[:,i-1,:]/2)
    # define the mass transport matrix at each grid point
    mass_residual = np.zeros((len(index_month),jj,ji),dtype=float)
    # calculate the mass residual based on continuity equation
    mass_residual = div_mass_flux_u + div_mass_flux_v
    # calculate the mass correction velocity field
    uc = np.zeros((len(index_month),jj,ji),dtype=float)
    vc = np.zeros((len(index_month),jj,ji),dtype=float)

    for i in np.arange(len(index_month)):
        uc[i,:,:] = mass_residual[i,:,:] * e1t / bathymetry * surface_mask
        vc[i,:,:] = mass_residual[i,:,:] * e2t / bathymetry * surface_mask

    return uc, vc, mass_residual, e1t_3D, e2t_3D, dz_3D, div_mass_flux_u, div_mass_flux_v

def meridional_energy_transport(theta_key, s_key, u_key, v_key, uc, vc):
    # extract variables
    print "Start extracting variables for the quantification of meridional energy transport."
    theta = theta_key.variables['thetao'][:] # the unit of theta is Celsius!
    #u = u_key.variables['uo'][:]
    v = v_key.variables['vo'][:]
    print 'Extracting variables successfully!'
    #logging.info("Extracting variables successfully!")
    # calculate heat flux at each grid point
    Internal_E_flux = np.zeros((len(index_month),level,jj,ji),dtype=float)
    for i in index_month:
        for j in np.arange(level):
            if j == 0:
                Internal_E_flux[i,j,:,:] = constant['rho'] * constant['cp'] * (v[i,j,:,:]-vc[i,:,:]) *\
                                      theta[i,j,:,:] * e1t * nav_lev[j] * tmask[j,:,:]
            else:
                Internal_E_flux[i,j,:,:] = constant['rho'] * constant['cp'] * (v[i,j,:,:]-vc[i,:,:]) *\
                                      theta[i,j,:,:] * e1t *(nav_lev[j]-nav_lev[j-1]) * tmask[j,:,:]
    # take the vertical integral
    Internal_E_int = np.zeros((len(index_month),jj,ji))
    Internal_E_int = np.sum(Internal_E_flux,1)/1e+12
    print '*****************************************************************************'
    print "**** Computation of meridional energy transport in the ocean is finished ****"
    print "************         The result is in tera-watt (1E+12)          ************"
    print '*****************************************************************************'

    return Internal_E_int

def visualization_model_basedmap(E,year):
    fig1 = plt.figure()
    # setup global Equidistant Cylindrical Projection
    m = Basemap(projection='cyl',llcrnrlat=-90,urcrnrlat=90,\
               llcrnrlon=-180,urcrnrlon=180,lon_0=0,lat_0=0,resolution='l')
    # draw coastlines
    m.drawcoastlines()
    # draw parallels and meridians
    m.drawparallels(np.arange(-90,91,30),labels=[1,1,0,0],fontsize = 8)
    m.drawmeridians(np.arange(-180,181,60),labels=[0,0,0,1],fontsize = 8)
    # x,y coordinate - lon, lat
    #xx, yy = np.meshgrid(nav_lon,nav_lat)
    XX, YY = m(nav_lon, nav_lat)
    # define color range for the contourf
    color = np.linspace(-2,2,21)
    # !!!!!take care about the coordinate of contourf(Longitude, Latitude, data(Lat,Lon))
    cs = m.contourf(XX,YY,E,color,cmap='coolwarm')
    # add color bar
    cbar = m.colorbar(cs,location="bottom",size='4%',pad="8%",format='%.1f')
    cbar.ax.tick_params(labelsize=8)
    #cbar.set_ticks(np.arange(-1,1.1,0.2))
    #cbar.set_ticklabels(np.arange(-1,1.1,0.2))
    cbar.set_label('TW',fontsize = 8)
    plt.title('Meridional Energy Transport in the Ocean from ORAS4 %d' % (year),fontsize = 9, y=1.05)
    plt.show()
    fig1.savefig(output_path_fig + os.sep + "OMET_ORAS4_%d.jpeg" % (year),dpi=500)

def regrid_visualization(E,nav_lat,nav_lon,mask):
    # mask E for visualization
    E_mask = np.ma.masked_where(mask == 0,E)
    # define the cube for the use of iris package
    latitude = iris.coords.AuxCoord(nav_lat,standard_name='latitude',units='degrees')
    longitude = iris.coords.AuxCoord(nav_lon,standard_name='longitude',units='degrees')
    cube_E = iris.cube.Cube(E_mask/1000,long_name='Oceanic Meridional Energy Transport',
                            var_name='OMET',units='PW',aux_coords_and_dims=[(latitude,(0,1)),(longitude,(0,1))])
    print cube_E
    # regridding plotting through Iris
    iris.FUTURE.netcdf_promote = True
    # choose the projection type
    projection = ccrs.PlateCarree()
    # Transform cube to target projection
    # The interpolation is accomplished by nearest-neighbor method
    cube_regrid, extent = iris.analysis.cartography.project(cube_E, projection, nx=360, ny=180)
    proj_y_coord = cube_regrid.coord('projection_y_coordinate').points
    proj_x_coord = cube_regrid.coord('projection_x_coordinate').points
    print cube_regrid
    fig2 = plt.figure()
    fig2.suptitle('ORCA1 Data Projected to PlateCarree')
    # Set up axes and title
    ax = plt.subplot(projection=ccrs.PlateCarree())
    # Set limits
    ax.set_global()
    # Draw coastlines
    ax.coastlines()
    # set gridlines and ticks
    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,linewidth=1,
                      color='gray', alpha=0.5,linestyle='--')
    gl.xlabels_top = False
    gl.xlabel_style = {'size': 11, 'color': 'gray'}
    #gl.xlines = False
    #gl.set_xticks()
    #gl.set_yticks()
    gl.xformatter = LONGITUDE_FORMATTER
    gl.ylabel_style = {'size': 11, 'color': 'gray'}
    #ax.ylabels_left = False
    gl.yformatter = LATITUDE_FORMATTER
    # plot with Iris quickplot pcolormesh
    qplt.pcolormesh(cube_regrid,cmap='coolwarm')
    iplt.show()
    fig2.savefig(output_path_fig + os.sep + 'T_grid' + os.sep + 'OMET_ORAS4_Mercator_mass_correct.jpg',dpi = 500)

    # extract the interpolated values from cube
    E_interpolation = cube_regrid.data

    return E_interpolation, proj_y_coord, proj_x_coord

def zonal_int_plot(E_point_interpolation,proj_y_coord):
    # take the zonal means
    E_zonal_int = np.sum(E_point_interpolation,1)
    fig3 = plt.figure()
    plt.plot(proj_y_coord,E_zonal_int)
    plt.xlabel("Latitude")
    plt.ylabel("Meridional Energy Transport (PW)")
    plt.show()
    fig3.savefig(output_path_fig + os.sep + 'T_grid' + os.sep + 'OMET_ORAS4_mass_correct.jpg',dpi = 500)

    return E_zonal_int

if __name__=="__main__":
    # create the year index
    period = np.arange(start_year,end_year+1,1)
    index_month = np.arange(12)
    # ORCA1_z42 infor (Madec and Imbard 1996)
    ji = 362
    jj = 292
    level = 42
    # extract the mesh_mask and coordinate information
    nav_lat, nav_lon, nav_lev, tmask, umask, vmask, e1t, e2t, mbathy = var_coordinate(datapath)
    # surface land-sea mask
    surface_mask = tmask[0,:,:]
    # calculate the maximum depth from bathymetry
    # attention! We should not mask the depth array for the sake of following computation
    max_bathy = np.zeros((jj,ji),dtype = float)
    for i in np.arange(jj):
        for j in np.arange(ji):
            counter = mbathy[i,j]
            max_bathy[i,j] = nav_lev[counter]
    #create a data pool to save the OMET for each year and month
    OMET_E_pool_point = np.zeros((len(period),12,jj,ji),dtype = float)
    #OMET_E_pool_zonal_int = np.zeros((len(period),12,jj,ji),dtype = float)
    # loop for calculation
    for i in period:
        # get the key of each variable
        theta_key, s_key, u_key, v_key = var_key(datapath, i)
        # mass corretion
        uc, vc, mass_residual, e1t_3D, e2t_3D, dz_3D, div_mass_flux_u, div_mass_flux_v = mass_correction_modified(u_key, v_key, max_bathy)
        # calculate the meridional energy transport in the ocean
        E_point = meridional_energy_transport(theta_key, s_key, u_key, v_key, uc, vc)
        OMET_E_pool_point[i-1980,:,:,:] = E_point
        # take the mean value over the entire year for basemap
        E_point_mean = np.mean(E_point,0)
        del E_point
        # visualization
        # The basemap module doesn't work since the data is not monotonic in any direction
        #visualization_model_basedmap(E_point_mean,i)
        # Tri-Polar Grid Projected plotting through Iris and Cartopy
        E_point_interpolation, proj_y_coord, proj_x_coord = regrid_visualization(E_point_mean,nav_lat,nav_lon,surface_mask)
        E_zonal_int = zonal_int_plot(E_point_interpolation, proj_y_coord)

print ("--- %s minutes ---" % ((tttt.time() - start_time)/60))
